# Most common questions
1. Git rebase, branches, commit etc.
2. Docker cmd/entrypoint etc.
3. 

# Interview plan 
Git - 
Terraform - ?
Monitroing - Grafana, Prometheus, Victoria Metrics, AlertManager, Tracing 
Ansible - what is role, playbook, compare with chief and puppet 
Kubernetes - tolaration and taints, node port, services

##########################################################################################################################################
# About LLM and AI
Don't forget about role
Example you write promt and tell "you are devops ingener" <<< it is role

##########################################################################################################################################
JWT (JSON Web Token) — это открытый стандарт (RFC 7519) для безопасной передачи данных между сторонами в формате JSON. Используется преимущественно для аутентификации и авторизации в клиент‑серверных приложениях.

Ключевые особенности
Компактность. Токены представляют собой строку, которую легко передавать через URL, HTTP‑заголовки или тело запроса.

Самодостаточность. Все необходимые данные (например, информация о пользователе) содержатся внутри токена — серверу не нужно обращаться к базе данных для проверки.

Безопасность. Токены подписываются секретным ключом, что гарантирует их целостность и подлинность. При использовании алгоритмов HMAC или RSA данные также шифруются.


##########################################################################################################################################
# CI/CD
CI
Result for CI it's artifact
build > test > artifact (artifact with tag and it's )
PIPLINE get code > Sonar > set tags for images, helm charts > build or without build > functionality test ()
CD 
It's already deploy application to stage, test or production

##########################################################################################################################################
# Linux 

##########################################################################################################################################
# Main questions about Kubernets 
1. `kubectl apply -f my-deployment.yaml`
   Пользователь отправляет команду через CLI (kubectl), указывая файл конфигурации YAML.

2. Запрос отправляется в API-сервер Kubernetes
   Команда передается на сервер API Kubernetes, который является точкой входа для всех операций управления кластером.

3. Проверка аутентификации и авторизации (AAA)
   API-сервер сначала проверяет подлинность пользователя (Authentication). Затем выполняется проверка прав доступа, чтобы убедиться, что запрашиваемый ресурс разрешен данному пользователю (Authorization).

4. Валидация ресурса
   Если доступ подтвержден, API-сервер проверяет корректность описания ресурса согласно спецификации Kubernetes (Validation).

5. Создание записи в etcd
   После успешной проверки, новая версия Deployment сохраняется в распределенной хранилище состояния etcd.

6. Controller Manager замечает изменения
   Контроллер контроллера Deployment постоянно следит за изменениями в etcd и обнаруживает новое состояние Deployment.

7. Контроллер создает реплики Pods
   Controller manager вызывает создание необходимых Pod'ов для достижения желаемого количества экземпляров приложения (Deployment spec).

8. Scheduler назначает Pod на Node
   Scheduler выбирает подходящую ноду (Node) для размещения каждого нового Pod'а исходя из доступности ресурсов и ограничений размещения.

9. Kubelet запускает контейнеры на выбранной ноде
   Kubelet на конкретной ноде получает инструкции от API-сервера и инициирует запуск контейнера (через Docker/Cri-o или другой runtime) с заданными параметрами.

kubectl → API Server → Authentication & Authorization → Validation → etcd → Controller Manager → Scheduler → Kubelet → Container Runtime

   # Scheduler and kubelet
   Изменение статуса Pod
   Как только Scheduler назначит Pod определённому узлу, этот факт записывается обратно в хранилище (etcd), и статус Pod меняется с Pending на Scheduled.
   
   Kubelet активируется на узле
   Компонент kubelet, работающий непосредственно на каждом узле, периодически запрашивает у API-сервера список новых назначенных Pod’ов. Обнаружив новые задания, kubelet приступает к процессу их исполнения.

   Kubelet запускает контейнеры

   - Проверяет наличие образа контейнера, указанного в описании Pod (если образ отсутствует, скачивает его);
   - Создаёт сетевое пространство (Network Namespace) и настраивает сети (например, CNI);
   - Запускает сам контейнер внутри выбранного пространства имен (namespace) через контейнерный движок (Docker, containerd и др.).

   # Docker, crio and containerd 
   Правильное обобщающее название для Docker, containerd и крио — это контейнерные рантаймы (или контейнерные среды выполнения)

   1. Scheduler определяет оптимальную ноду для Pod и записывает эту информацию в etcd.
   2. Kubelet на соответствующей ноде замечает появление нового Pod'а.
   3. Kubelet взаимодействует с контейнерным рантаймом (например, Docker или containerd):
   - Скачивается нужный образ (при необходимости).
   - Создаются необходимые структуры для запуска (сетевые настройки, PID namespace и т.д.)
   - Контейнеры стартуют.
   
   # About container run time
   - Container: Контейнер (англ. container) — стандартизированная единица программного обеспечения, включающая приложение вместе с зависимостями (библиотеки, конфигурационные файлы и т.д.). Основная цель            контейнеров — упрощение упаковки и распространения приложений.

   - Runtime: Окружение выполнения (англ. runtime environment) — среда, обеспечивающая выполнение программы или контейнера, включая систему виртуализации, процессы изоляции и управление ресурсами.
     То есть, container runtime — это окружение, инфраструктура и инструменты, позволяющие создавать, запускать и управлять контейнерами, обеспечивая изоляцию процессов, управление ресурсами и взаимодействие с      хост-машиной.
### nodePort
Issue:
при использовании сервиса с типом NodePort, запросы отправляются на IP конкретного узла (ноды), и если Pod перемещается на другую ноду,
вам придётся вручную отслеживать IP адреса и перенаправлять трафик туда
Resolution:
Даже если под переехал на другую ноду, вы по‑прежнему можете:
стучаться в IP_любой_ноды:30005;
получать ответ от пода (Kubernetes маршрутизирует трафик).

Благодаря правилам iptables на ноде B, запрос автоматически перенаправляется на соответствующую ноду A, где размещён реальный Pod.
Сервис успешно обрабатывает запрос и возвращает ответ клиенту.

### pause image
невозможно запустить полноценные контейнеры сразу одновременно. Нужен некоторый минимальный инструмент для начальной подготовки общего окружения и пространства имён. Поэтому появился специально облегчённый образ, выполняющий минимум необходимой функциональности.

Обычно размер pause-образа составляет буквально несколько мегабайт, поскольку его задача крайне ограниченна.

### Strategy for deployments
Rolling update 
- Новые Pod'ы создаются последовательно.
- Старые Pod'ы удаляются поэтапно.
- Можно задать максимальное количество временно избыточных (maxSurge) и отключаемых (maxUnavailable) Pod'ов.
Recreate 
- Сначала прекращаются все работающие Pod'ы.
- Только потом разворачиваются новые Pod'ы.
Blue Green deployment
- Развёрнута первая стабильная версия («синяя»).
- Параллельно развёртывается вторая версия («зелёная») отдельно.
- Производится постепенное тестирование и верификация зелёной версии.
- Переключение пользователей осуществляется сменой маршрутов в сервисе или Ingress-е.
Canary Release (Тестирование малых групп пользователей)
- Постепенное увеличение доли пользователей, переходящих на новую версию.
- Тестирование небольшой группы пользователей до полного перевода всех пользователей на новую версию.
A/B Testing (Тестирование двух версий параллельно)
- Одновременное размещение обеих версий и выбор лучшей по результатам теста.

### Deployment, daemonset, statefulset
Deployment → для stateless‑сервисов с гибким масштабированием.

StatefulSet → для stateful‑приложений с уникальными подами и постоянными данными.

DaemonSet → для системных агентов, которые должны работать на каждой ноде.

StatefulSet
Назначение: управление статусными (stateful) приложениями, где важны:
уникальность подов;
упорядоченность операций;
стабильные сетевые идентификаторы.

Ключевые особенности:
Поды получают уникальные имена (web-0, web-1 и т. д.).
Стабильные идентификаторы: каждый под имеет:
постоянное DNS‑имя (web-0.my-service.namespace.svc.cluster.local);
закреплённый PVC (PersistentVolumeClaim) даже при переезде на другую ноду.
Упорядоченное масштабирование: добавление/удаление подов по порядку (0 → 1 → 2).
Упорядоченные обновления: по одному поду, с контролем состояния.
Примеры: базы данных (MySQL, PostgreSQL), кластеры (Kafka, Elasticsearch).
Когда использовать: когда приложение требует:
сохранения локальных данных;
чёткой нумерации подов;
предсказуемой сетевой идентификации.

# Taint and toleration 
Taint(зараза)
Официальное значение: метка на ноде, которая отпугивает поды.
Как работает: если на ноде стоит taint, по умолчанию на неё нельзя запланировать поды — они «боятся» этой ноды.
yaml
taints:
  - key: "dedicated"
    value: "gpu"
    effect: "NoSchedule"
Эффекты (самые частые):

NoSchedule — не планировать поды без toleration.
PreferNoSchedule — стараться не планировать, но можно.
NoExecute — выгнать уже работающие поды (если у них нет toleration).

Toleration («противоядие»)
Официальное значение: разрешение для пода «терпеть» определённый taint.
Как работает: если у пода есть toleration, соответствующий taint ноды его не отпугивает — под может быть запланирован.
yaml
tolerations:
  - key: "dedicated"
    operator: "Equal"
    value: "gpu"
    effect: "NoSchedule"

# Metric server
Что такое Metrics Server
Metrics Server — это компонент Kubernetes, который:
собирает базовые метрики использования ресурсов (CPU, память) с нод и подов;
предоставляет их через Kubernetes API (metrics.k8s.io/v1beta1);
служит источником данных для:
команды kubectl top;
Horizontal Pod Autoscaler (HPA);
других инструментов мониторинга.
Как работает:
Под Metrics Server запускается в кластере (обычно в namespace kube-system).
Периодически опрашивает Kubelet на каждой ноде через API.
Агрегирует данные и выкладывает их в API Kubernetes.
kubectl top и HPA запрашивают метрики через этот API.

Установите Metrics Server (если отсутствует)
Официальный манифест:
kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml
kubectl get pods -n kube-system -l k8s-app=metrics-server
kubectl get deployment metrics-server -n kube-system

# Liveness and Readiness probes
initialDelaySeconds
Это параметр в настройках livenessProbe и readinessProbe, который задаёт:
сколько секунд Kubernetes должен подождать после запуска контейнера, прежде чем начать выполнять проверки probe.
Зачем нужен:
Дать приложению время на «разогрев» (загрузка конфигураций, подключение к БД, инициализация кешей).
Избежать ложных срабатываний («приложение не отвечает!»), пока оно ещё стартует.

containers:
- name: my-app
  image: my-image:latest
  livenessProbe:
    httpGet:
      path: /health
      port: 8080
    initialDelaySeconds: 30  # ждать 30 сек после старта контейнера
    periodSeconds: 10     # потом проверять каждые 10 сек
  readinessProbe:
    httpGet:
      path: /ready
      port: 8080
    initialDelaySeconds: 20  # ждать 20 сек перед первой проверкой
    periodSeconds: 5      # потом проверять каждые 5 сек

initialDelaySeconds: задержка перед первой проверкой.
periodSeconds: интервал между проверками (по умолчанию 10 сек).
timeoutSeconds: сколько ждать ответа probe (по умолчанию 1 сек).
successThreshold: сколько успешных проверок нужно для «выздоровления» (по умолчанию 1).
failureThreshold: сколько неудач до срабатывания (для liveness — перезапуск; для readiness — исключение из балансировки).

# Type of services k8s

ClusterIP
для внутренних микросервисов (БД, кэш, бэкенды);
когда не нужен внешний доступ или потом обеспечить доступ через ingress/harproxy 

nodePort:
для быстрого тестирования;
если нет балансировщика нагрузки.

LoadBalancer:
для продакшен‑приложений с внешним доступом;
когда нужна высокая доступность и автоматическая балансировка.
(Даже для LoadBalancer создаётся ClusterIP (внутри кластера), балансировщик не общается напрямую с подами — только через ClusterIP и kube‑proxy.)

ExternalName:
чтобы сослаться на внешний сервис (например, SaaS) через Kubernetes‑DNS;
для миграции (временно направить трафик вовне).



# Gateway API



##########################################################################################################################################
# GIT 
### How to move commit from branch to another branch 
Шаг 1: Узнай SHA-хэш нужного коммита.
Для этого используй команду:
git log
Выбери нужный коммит по описанному сообщению или дате, запомни его SHA-хэш (это длинная строка типа abcdef123456...).
Шаг 2: Переключись на нужную ветку, куда хочешь перенести коммит.
git checkout feature
Шаг 3: Переноси коммит в новую ветку с помощью команды cherry-pick.
git cherry-pick abcdef123456
Git применит выбранный коммит в твою текущую ветку.

### With rebase 
Перемещение коммита через rebase
Этот способ подходит, если надо переместить целую серию коммитов или перестроить историю ветки.

### About rebase 
Rebase — это способ перестройки истории изменений в репозитории Git таким образом, чтобы твоя ветвь выглядела так, будто твои изменения были сделаны поверх самой свежей версии основного кода.
Другими словами, представь, что ты работаешь над своей задачей, создавая новую ветку от главной (main). Пока ты вносишь свои изменения, кто-то другой параллельно обновил главную ветку (main), добавив туда новые коммиты.
Теперь у тебя есть два варианта синхронизации твоей ветки с изменениями главной ветви:
1. Merge (слияние) — объединить свою ветку с главным путём добавления нового специального коммита ("merge-commit"), который объединяет обе ветки.
2. Rebase (перестройка) — переписать историю твоей ветки так, чтобы твои изменения казались сделанными после свежих изменений в главной ветке.


##########################################################################################################################################
# Networks
| Устройство  |      IP      |     Маска     |
| ----------- | ------------ | ------------- |
| Компьютер A | 192.168.1.10 | 255.255.255.0 |
| Компьютер B | 192.168.1.20 | 255.255.255.0 |
Компьютеры находятся в одной подсети (192.168.1.x), поэтому взаимодействие возможно напрямую, даже если шлюз не настроен. (через ARP-протокол, определяя MAC-адреса друг друга)

##########################################################################################################################################
# API Methods
Kinds of methods and how does it works?
GET - Метод GET используется для получения ресурсов. Это самый простой метод, предназначенный для извлечения данных с сервера. Основные характеристики метода GET:
- Запросы передаются через адресную строку браузера (URL), включая параметры в строке запроса.
- Данные видны пользователям и индексируются поисковиками.
- Безопасен и идемпотентен (не меняет состояние ресурса).
- Ограничение на длину строки запроса (~2048 символов в зависимости от реализации браузером).

POST - Метод POST предназначен для отправки данных на сервер для обработки. Обычно используется для передачи больших объёмов данных, формы, загрузки файлов и прочих операций, изменяющих состояние системы. Особенности метода POST:
- Данные отправляются внутри тела запроса, скрытые от пользователей.
- Нет ограничений на размер передаваемых данных.
- Может изменять состояние на стороне сервера (например, создавать новые записи).
- Индексация поисковиками невозможна

PUT - Используется для обновления существующего ресурса или создания нового ресурса с указанным путём. Если ресурс существует, он обновляется, иначе создаётся новый. Отличается от POST, так как имеет строгое назначение пути ресурса.

DELETE - Удаляет указанный ресурс с сервера. Этот метод считается безопасным и идемпотентным, поскольку повторные запросы приводят к одному и тому же результату (если ресурс удалён ранее, последующие DELETE-запросы завершатся успешно).

PATCH - Применяется для частичного изменения ресурса. Полезен, когда нужно обновить лишь некоторые поля ресурса, не затрагивая весь объект целиком.

HEAD - Похож на метод GET, но возвращает только заголовки ответа, без самого содержимого. Используется для проверки доступности ресурса, получения метаданных (размер файла, тип контента и т.п.).

OPTIONS - Запрашивает доступные методы для указанного ресурса. Часто применяется для тестирования API-интерфейсов и кросс-доменных запросов.

##########################################################################################################################################
# Databases
PostgresSQL about sunc and async
## Синхронная запись данных означает, что приложение ожидает подтверждения завершения операции записи от базы данных перед продолжением своей работы. Этот подход гарантирует высокую степень надежности, так как клиент точно знает, была ли операция успешной или произошла ошибка.

Преимущества синхронной записи:
- Высокая надёжность: транзакция гарантированно выполнена успешно либо откатана в случае сбоя.
- Легко отслеживать состояние операций и управлять ими.

Недостатки:
- Потенциально низкая производительность, особенно при большом количестве параллельных операций, так как каждая операция должна дождаться своего подтверждения.

Примеры ситуаций, когда предпочтительна синхронная запись:
- Финансовые транзакции, где критически важна целостность данных.
- Логирование важных действий пользователей (например, регистрация аккаунта).

## Асинхронная запись позволяет приложению продолжить выполнение сразу же после отправки команды записи в базу данных, не дожидаясь её завершения. В этом режиме клиент отправляет команду на запись и продолжает работу дальше, не ожидая результата.

Преимущества асинхронной записи:
- Высокое быстродействие и масштабируемость: система не простаивает, ожидая результатов каждой отдельной операции.
- Повышенная пропускная способность, особенно при больших объемах записей.

Недостатки:
- Сложнее контролировать успех операции записи: если база данных не подтвердила успешность операции, приложение может оказаться в неопределённом состоянии.
- Возможность потери данных при отказе оборудования или сети.

Примеры ситуаций, когда оправдан выбор асинхронной записи:
- Сбор статистики и аналитики, где потеря отдельных записей менее критична.
- Операции, создающие большое количество мелких изменений в базе данных, которые легко восстанавливаются вручную.
## RabbitMQ 
How to check that consumer consume messages just check queue in rabbitmq
if you have more than 1 host may be 5, so you can use script to watch all queues pn all hosts

## WAL 
WAL (Write Ahead Log) — это метод журналирования изменений в базе данных, используемый для повышения надежности и восстановления базы данных после сбоев. Суть метода заключается в следующем:
Как работает Write Ahead Logging?
При любом изменении данных (например, вставке, обновлении или удалении записей):
1. Запись журнала: Прежде чем изменения будут записаны непосредственно в базу данных, система сначала фиксирует эти изменения в специальном журнале транзакций (лог-файл). Это делается заранее ("write ahead"), отсюда и название метода.
2. Подтверждение транзакции: После записи всех необходимых операций в журнал, база данных подтверждает успешное завершение транзакции клиенту. Только после подтверждения транзакции начинается запись данных в основную таблицу.
3. Фиксация данных: Данные постепенно переносятся из журнала в саму базу данных в фоновом режиме либо синхронно в зависимости от настроек системы.

##########################################################################################################################################
# Ansible
Идемпотентность: Ansible не переустанавливает пакет, если он уже есть. В Go нужно проверять вручную (например, dpkg -l | grep pkg).

# ##########################################################################################################################################
# Docker 
COPY vs ADD 
### ADD
- Что делает: Копирует файлы и директории из локальной файловой системы хоста внутрь контейнера.
- Особенности:
  - Может скачивать удалённые архивы (tar.gz) непосредственно из сети по ссылке и распаковывать их автоматически внутри образа.
  - Поддерживает автоматическое извлечение архивов (*.tar, *.tar.gz, *.tgz), если копируется файл с расширением .tar.
  - Если файл имеет расширение .tar, .tar.gz или .tgz, Docker автоматически распакует его в целевой каталог.
### example:
ADD https://example.com/file.tar /target/directory/
Note: Add имеет возможность еще ходить куда-то на внешние ресурсы и стягивать оттуда данные

### COPY
- Что делает: Точно такая же операция, как и ADD, но без поддержки загрузки файлов из Интернета и автоматического распаковки архивов.
- Особенности:
  - Работает быстрее и проще, поскольку не поддерживает загрузку удалённых ресурсов и распаковку.
  - Рекомендуется использовать именно её, если вам не нужны дополнительные возможности ADD. Это улучшает читаемость Dockerfile и снижает вероятность ошибок.

### CMD vs ENTRYPOINT
### CMD
- Что делает: Предоставляет команду по умолчанию, которая запускается контейнером при старте.
- Особенности:
  - Является аргументом по умолчанию для команды, указанной в ENTRYPOINT.
  - Можно переопределять командой запуска контейнера, передавая ей новые аргументы.
  - Удобно использовать, если приложение допускает гибкость в параметрах запуска.

CMD ["executable","param1","param2"] # JSON format (рекомендуемый)
CMD command param1 param2              # Shell format
### example:
CMD ["python", "app.py"] or CMD ["./master-npd"] or CMD ["./manager-ns"]

### ENTRYPOINT
- Что делает: Определяет исполняемый файл, который обязательно запустится при старте контейнера.
- Особенности:
  - Используется вместе с CMD: команда из CMD становится аргументами для команды из ENTRYPOINT.
  - Полезно применять для приложений, которым необходимы фиксированные параметры запуска.
  - Переопределение возможно только полным перезапуском всего процесса (например, использование другого скрипта).

ENTRYPOINT ["executable", "param1", "param2"] # JSON format (рекомендуемый)
ENTRYPOINT executable param1 param2           # Shell format
### example:
ENTRYPOINT ["python"]
CMD ["app.py"]
CMD задаёт параметры по умолчанию, которые легко переопределяются, а ENTRYPOINT определяет основной исполняемый процесс, который сложно изменить при запуске контейнера.

### another example
Представьте себе сценарий, где мы хотим запустить скрипт Python с разными параметрами каждый раз при запуске контейнера. Например, у вас есть разные режимы работы приложения, зависящие от передаваемых аргументов.
Допустим, ваше приложение называется run.py, и оно принимает два разных режима работы:
- Режим чтения данных: read_data
- Режим записи данных: write_data

Example Dockerfile
FROM python:3.8-slim
WORKDIR /app
# Скопируем исходники
COPY . .
# Укажите стандартную команду для запуска
CMD ["python", "run.py", "read_data"]

Теперь при запуске контейнера:
- По умолчанию выполняется python run.py read_data, потому что это записано в команде CMD.
- Но если нам нужно другое поведение, скажем, запись данных, мы можем передать новый аргумент при запуске контейнера:
docker run my_image python run.py write_data <<<<< change read to write !!! when try to run our application
Здесь важно отметить, что команда из CMD изменяется прямо при запуске контейнера.

Например, пусть у нас есть веб-приложение Flask, которое должно стартовать сервер и передавать любые дополнительные параметры, как IP-адрес или номер порта.

Dockerfile может выглядеть следующим образом:

dockerfile

FROM python:3.8-slim

WORKDIR /app

# Скопируем исходники
COPY . .

# Установим пакет
RUN pip install flask

# Используем ENTRYPOINT для запуска сервера
ENTRYPOINT ["flask", "run"] <<< неизменна и всегда выполнятеся 

# Передадим стандартный адрес и порт
CMD ["--host=0.0.0.0", "--port=5000"] <<<  а уже через CMD  можно изменить аргументы ну или Deployment 
При таком подходе:

- Когда вы запускаете контейнер без дополнительных аргументов, Docker выполнит flask run --host=0.0.0.0 --port=5000.
- Однако если вам нужно задать нестандартный хост или порт, вы можете сделать это прямо при запуске контейнера:

docker run my_image --host=127.0.0.1 --port=8000
И вот ключевое отличие:

- Команда из ENTRYPOINT неизменна и должна обязательно выполняться.
- Аргумент из CMD меняется динамически при каждом запуске контейнера.

Так что итоговая последовательность действий выглядит так:
- Сначала выполняется команда из ENTRYPOINT, затем ей передаются аргументы из CMD.
▌ Итог:
- Используйте CMD, если хотите иметь возможность менять команду при запуске контейнера.
- Применяйте ENTRYPOINT, если ваша программа должна гарантированно начать работу с конкретного исполняемого файла или команды, и дальнейшие изменения возможны лишь в виде дополнительных аргументов.

### Example with my Dockerfile
FROM registry.apps.k8s.<my-registry>/golang/golang:1.24.0   AS builder
WORKDIR /app
COPY go.mod go.sum ./
COPY vendor/ ./vendor/
COPY . .
RUN CGO_ENABLED=0 GOOS=linux GOARCH=amd64 go build -o master-npd main-npd/master-npd/cmd/main.go

FROM registry.apps.k8s.<my-registry>/alpine/alpine:3.22.1
WORKDIR /app
COPY --from=builder /app/master-npd /app/
RUN  chmod u+x master-npd && mkdir /certs  /files
CMD ["./master-npd"]
### Здесь CMD лучше сменить на ENTRYPOINT так как кроме своего binary я более ничего не запускаю 

##########################################################################################################################################
# ArgoCD
Background and Foreground 
Argo CD различает два режима удаления ресурсов при выполнении синхронизаций: Foreground Deletion и Background Deletion. Рассмотрим каждый режим детально:

▌ Foreground Deletion (Удаление переднего плана)

Режим foreground deletion подразумевает удаление ресурсов синхронно. Argo CD ждёт, пока зависящие ресурсы завершатся естественным образом, прежде чем удалить родительский ресурс.

Этот метод полезен, когда существуют зависимости между ресурсами, и требуется гарантия последовательного удаления, чтобы предотвратить нежелательные побочные эффекты. Например, если у вас есть Deployment и связанный с ним Service, Argo CD дождётся, пока все Pod'ы перестанут обслуживать трафик, прежде чем удалять Deployment.

Преимущества:

- Последовательное удаление, снижающее вероятность возникновения ошибок.
- Полностью управляемое поведение.

Недостатки:

- Может занять больше времени, особенно если ресурсы имеют долгую процедуру освобождения.

▌ Background Deletion (Удаление заднего плана)

Режим background deletion позволяет быстро удалить ресурсы, передав очистку зависимых ресурсов соответствующему контроллеру Kubernetes. Удаление производится асинхронно, без ожидания окончания всех подчинённых ресурсов.

Преимуществом этого метода является скорость удаления. Недостатком — отсутствие контроля над порядком удаления ресурсов, что может привести к временным ошибкам, если зависимые ресурсы ещё работают.

Преимущества:

- Быстрое удаление.
- Подходит для простых сценариев, где порядок удаления не критичен.

Недостатки:

- Возможны временные ошибки, вызванные некорректным порядком удаления.
When you try to delete via WEBUI argo as you about how to delete it in Foreground or Background
